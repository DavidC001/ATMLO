seed: 42

out_dir: "results"

data_preprocessing:
  dataset_dir: "datasets"

  input_jsons: [
    "datasets/LogicBench/LogicBench(Aug)/propositional_logic/modus_tollens/data.json",
    "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/modus_tollens/data.json",
  ]

  model_names: [
    "EleutherAI/pythia-14m",
    "gpt2-small",
    "EleutherAI/pythia-410m",
    "Qwen/Qwen2.5-0.5B-Instruct",
    "bigscience/bloom-1b1",
    "Qwen/Qwen2.5-1.5B-Instruct",
    "meta-llama/Llama-3.2-1B-Instruct",
    "meta-llama/Llama-3.2-3B-Instruct",
  ]

  templates: [
    "alpaca",
    "alpaca",
    "alpaca",
    "qwen",
    "alpaca",
    "qwen",
    "llama_3",
    "llama_3",
  ]


model:
  # model_name: "meta-llama/Llama-3.2-1B-Instruct" # AROUND 50
  # model_name: "gpt2-small" AROUND 50
  # model_name: 'EleutherAI/pythia-410m' # WORSE THAN RANDOM
  # model_name: 'EleutherAI/pythia-14m'
  # model_name: 'bigscience/bloom-1b1' looks like 50
  # model_name: "Qwen/Qwen2.5-3B-Instruct" AROUND 70 takes around 10h for 1 (out of 20)
  model_name: "Qwen/Qwen2.5-1.5B-Instruct" # AROUND 70 takes around 2h
  # model_name: "Qwen/Qwen2.5-0.5B-Instruct" #WORSE THAN RANDOM
  device: "cuda"
  
  batch_size: 16
  train_percent: 0.8

  threshold: 5e-3
