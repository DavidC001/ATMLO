exp_name: "ACDC_converted"

seed: 42

out_dir: "results"

benchmark:
  dataset_dir: "datasets"
  global_padding: False

  input_jsons: {
    # modus_tollens: [
    #   "LogicBench/data/LogicBench(Aug)/propositional_logic/modus_tollens/data_instances.json",
    #   "LogicBench/data/LogicBench(Eval)/BQA/propositional_logic/modus_tollens/data_instances.json",
    # ],
    # bidirectional_dilemma: [
    #   "LogicBench/data/LogicBench/LogicBench(Aug)/propositional_logic/bidirectional_dilemma/data_instances.json",
    #   "LogicBench/data/LogicBench/LogicBench(Eval)/BQA/propositional_logic/bidirectional_dilemma/data_instances.json",
    # ],
    # commutation: [
    #   "LogicBench/data/LogicBench/LogicBench(Aug)/propositional_logic/commutation/data_instances.json",
    #   "LogicBench/data/LogicBench/LogicBench(Eval)/BQA/propositional_logic/commutation/data_instances.json",
    # ],
    # constructive_dilemma: [
    #   "LogicBench/data/LogicBench/LogicBench(Aug)/propositional_logic/constructive_dillema/data_instances.json",
    #   "LogicBench/data/LogicBench/LogicBench(Eval)/BQA/propositional_logic/constructive_dilemma/data_instances.json",
    # ],
    # destructive_dilemma: [
    #   "LogicBench/data/LogicBench/LogicBench(Aug)/propositional_logic/destructive_dillema/data_instances.json",
    #   "LogicBench/data/LogicBench/LogicBench(Eval)/BQA/propositional_logic/destructive_dilemma/data_instances.json",
    # ],
    # disjunctive_syllogism: [
    #   "LogicBench/data/LogicBench/LogicBench(Aug)/propositional_logic/disjunctive_syllogism/data_instances.json",
    #   "LogicBench/data/LogicBench/LogicBench(Eval)/BQA/propositional_logic/disjunctive_syllogism/data_instances.json",
    # ],
    # hypothetical_syllogism: [
    #   "LogicBench/data/LogicBench/LogicBench(Aug)/propositional_logic/hypothetical_syllogism/data_instances.json",
    #   "LogicBench/data/LogicBench/LogicBench(Eval)/BQA/propositional_logic/hypothetical_syllogism/data_instances.json",
    # ],
    # material_implication: [
    #   "LogicBench/data/LogicBench/LogicBench(Aug)/propositional_logic/material_implication/data_instances.json",
    #   "LogicBench/data/LogicBench/LogicBench(Eval)/BQA/propositional_logic/material_implication/data_instances.json",
    # ],
    converted_modus_tollens: [
      "datasets/converted/modus_tollens/aug.json",
      "datasets/converted/modus_tollens/eval.json",
    ],
  }

  model_names: [
    # "EleutherAI/pythia-14m",
    # "gpt2-small",
    # "EleutherAI/pythia-410m",
    # "Qwen/Qwen2.5-0.5B-Instruct",
    # "Qwen/Qwen2.5-1.5B-Instruct",
    # "meta-llama/Llama-3.2-1B-Instruct",
    # "gpt2",
  ]

  templates: [
    # "alpaca",
    # "alpaca",
    # "alpaca",
    "qwen",
    "qwen",
    # "llama_3",
    # "alpaca",
  ]


circuit_discovery:
  # model_name: "meta-llama/Llama-3.2-1B-Instruct"
  # model_name: "gpt2-small"
  # model_name: "gpt2-xl"
  # model_name: 'EleutherAI/pythia-410m'
  # model_name: 'EleutherAI/pythia-14m'
  # model_name: "Qwen/Qwen2.5-1.5B-Instruct"
  model_name: "Qwen/Qwen2.5-0.5B-Instruct"
  device: "cuda"
  
  dataset: "converted_modus_tollens"

  batch_size: 8
  train_percent: 0.8

  threshold: 5e-3

  tokenGraph: False

  method: "ACDC" # "mask_gradient" or "ACDC" or "edge_attribution_patching"

  tao_exps: [-2]
  tao_bases: [5]


# probing_data:

# probing_exp:


convert_dataset:
  model: "meta-llama/Llama-3.1-70B-Instruct"

  dataset_files: [
    "LogicBench/data/LogicBench(Aug)/propositional_logic/modus_tollens/data_instances.json",
    "LogicBench/data/LogicBench(Eval)/BQA/propositional_logic/modus_tollens/data_instances.json",
  ]
  output_files: [
    "datasets/converted/modus_tollens/aug.json",
    "datasets/converted/modus_tollens/eval.json",
  ]
  format: [
    "modus_tollens",
    "modus_tollens",
  ]