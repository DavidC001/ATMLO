exp_name: "ACDC"

seed: 42

out_dir: "results"

data_preprocessing:
  dataset_dir: "datasets"
  global_padding: False

  input_jsons: {
    # modus_tollens: [
    #   "datasets/LogicBench/LogicBench(Aug)/propositional_logic/modus_tollens/data.json",
    #   "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/modus_tollens/data.json",
    # ],
    # bidirectional_dilemma: [
    #   "datasets/LogicBench/LogicBench(Aug)/propositional_logic/bidirectional_dilemma/data.json",
    #   "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/bidirectional_dilemma/data.json",
    # ],
    # commutation: [
    #   "datasets/LogicBench/LogicBench(Aug)/propositional_logic/commutation/data.json",
    #   "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/commutation/data.json",
    # ],
    # constructive_dilemma: [
    #   "datasets/LogicBench/LogicBench(Aug)/propositional_logic/constructive_dillema/data.json",
    #   "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/constructive_dilemma/data.json",
    # ],
    # destructive_dilemma: [
    #   "datasets/LogicBench/LogicBench(Aug)/propositional_logic/destructive_dillema/data.json",
    #   "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/destructive_dilemma/data.json",
    # ],
    # disjunctive_syllogism: [
    #   "datasets/LogicBench/LogicBench(Aug)/propositional_logic/disjunctive_syllogism/data.json",
    #   "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/disjunctive_syllogism/data.json",
    # ],
    hypothetical_syllogism: [
      "datasets/LogicBench/LogicBench(Aug)/propositional_logic/hypothetical_syllogism/data.json",
      "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/hypothetical_syllogism/data.json",
    ],
    # material_implication: [
    #   "datasets/LogicBench/LogicBench(Aug)/propositional_logic/material_implication/data.json",
    #   "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/material_implication/data.json",
    # ],
  }

  model_names: [
    # "EleutherAI/pythia-14m",
    # "gpt2-small",
    # "EleutherAI/pythia-410m",
    "Qwen/Qwen2.5-0.5B-Instruct",
    # "Qwen/Qwen2.5-1.5B-Instruct",
    # "meta-llama/Llama-3.2-1B-Instruct",
    # "gpt2",
  ]

  templates: [
    # "alpaca",
    # "alpaca",
    # "alpaca",
    "qwen",
    # "qwen",
    # "llama_3",
    # "alpaca",
  ]


circuit_discovery:
  # model_name: "meta-llama/Llama-3.2-1B-Instruct"
  # model_name: "gpt2-small"
  # model_name: "gpt2-xl"
  # model_name: 'EleutherAI/pythia-410m'
  # model_name: 'EleutherAI/pythia-14m'
  # model_name: 'bigscience/bloom-1b1'
  # model_name: "Qwen/Qwen2.5-1.5B-Instruct"
  model_name: "Qwen/Qwen2.5-0.5B-Instruct"
  device: "cuda"
  
  dataset: "hypothetical_syllogism"

  batch_size: 1
  train_percent: 0.8

  threshold: 5e-3

  tokenGraph: False

  method: "ACDC" # "mask_gradient" or "ACDC" or "edge_attribution_patching"

  tao_exps: [-2]
  tao_bases: [5]


# probing_data:

# probing_exp:


convert_dataset:
  model: "meta-llama/Llama-3.1-70B-Instruct"

  dataset_files: [
    "datasets/LogicBench/LogicBench(Aug)/propositional_logic/hypothetical_syllogism/data.json",
    "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/hypothetical_syllogism/data.json",
  ]
  output_files: [
    "datasets/LogicBench/LogicBench(Aug)/propositional_logic/hypothetical_syllogism/data.json",
    "datasets/LogicBench/LogicBench(Eval)/BQA/propositional_logic/hypothetical_syllogism/data.json",
  ]
  format: [
    "modus_tollens", # only general and modus_tollens are supported
    "modus_tollens",
  ]